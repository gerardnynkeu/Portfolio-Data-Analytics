{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10626738,"sourceType":"datasetVersion","datasetId":6579570}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Table of Contents**\n1. [Introduction](#1-introduction)  \n2. [Data Overview](#2-data-overview)  \n3. [Loading the Dataset](#3-loading-the-dataset)  \n4. [Exploratory Data Analysis (EDA)](#4-exploratory-data-analysis-eda)  \n   - 4.1 [Checking Missing Values](#41-checking-missing-values)  \n   - 4.2 [Detecting Duplicates](#42-detecting-duplicates)  \n   - 4.3 [Handling Data Types](#43-handling-data-types)  \n   - 4.4 [Identifying Outliers](#44-identifying-outliers)  \n   - 4.5 [Feature Distribution](#45-feature-distribution)  \n5. [Data Cleaning](#5-data-cleaning)  \n   - 5.1 [Handling Missing Values](#51-handling-missing-values)  \n   - 5.2 [Fixing Data Inconsistencies](#52-fixing-data-inconsistencies)  \n   - 5.3 [Removing Duplicates](#53-removing-duplicates)  \n   - 5.4 [Correcting Data Types](#54-correcting-data-types)  \n   - 5.5 [Handling Outliers](#55-handling-outliers)  \n6. [Final Cleaned Data Overview](#6-final-cleaned-data-overview)  \n7. [Data Visualization & Insights](#7-data-visualization--insights)  \n   - 7.1 [Sales Trends Over Time](#71-sales-trends-over-time)  \n   - 7.2 [Customer Segmentation](#72-customer-segmentation)  \n   - 7.3 [Top-Selling Products](#73-top-selling-products)  \n   - 7.4 [Regional Sales Analysis](#74-regional-sales-analysis)  \n   - 7.5 [Discount vs Profit Relationship](#75-discount-vs-profit-relationship)\n8.  [Tools & Technologies](#8-pools-&-Technologies)\n9. [Conclusion](#9-conclusion)  \n\n","metadata":{"execution":{"iopub.status.busy":"2025-02-19T14:11:35.715018Z","iopub.execute_input":"2025-02-19T14:11:35.716334Z","iopub.status.idle":"2025-02-19T14:11:35.743910Z","shell.execute_reply":"2025-02-19T14:11:35.723495Z"}}},{"cell_type":"markdown","source":"# 1- introduction","metadata":{}},{"cell_type":"markdown","source":"This project focuses on cleaning and analyzing an AI-generated e-commerce dataset using R. The dataset simulates real-world transactional data, including order details, customer segmentation, product categories, and financial metrics such as sales, discounts, profit, and shipping costs. The goal is to detect and fix data quality issues, transform the data for analysis, and extract meaningful business insights.","metadata":{}},{"cell_type":"markdown","source":"# 2- data overview","metadata":{}},{"cell_type":"markdown","source":"The dataset consists of 10,000 rows and 22 columns, with the following key attributes:\n\n    Order Information: Order ID, Order Date, Ship Date, Payment Method\n    Customer Details: Customer ID, Name, Segment, Region\n    Product Details: Product Category, Subcategory, Quantity, Discount\n    Financial Metrics: Sales, Profit, Shipping Cost\n\n‚ö†Ô∏è Data Quality Issues & Cleaning Steps\n\nThis dataset contains inconsistencies, missing values, and incorrect data types, making it an ideal case for data cleaning. The following steps were performed:\n‚úî Handling Missing Values ‚Äì Imputed missing numerical data with the median and categorical data with the mode.\n‚úî Fixing Data Inconsistencies ‚Äì Standardized text formatting (e.g., country and product names).\n‚úî Removing Duplicates ‚Äì Identified and removed duplicate entries.\n‚úî Correcting Data Types ‚Äì Converted columns to appropriate formats (dates, numeric, categorical).\n‚úî Handling Outliers ‚Äì Detected extreme values using IQR and replaced them with the median.\nüìä Data Analysis & Insights\n\nAfter cleaning, the dataset was used for exploratory data analysis (EDA) to uncover business insights:\n\n    üìà Sales Trends Over Time ‚Äì Identified seasonal patterns and peak sales periods.\n    üë• Customer Segmentation ‚Äì Analyzed customer groups to optimize marketing strategies.\n    üèÜ Top-Selling Products ‚Äì Ranked products based on sales and profitability.\n    üåç Regional Sales Performance ‚Äì Compared sales across different regions.\n    üí∞ Discount vs. Profit Relationship ‚Äì Evaluated how discounts impact profitability.\n\nüõ† Tools & Technologies Used\n\n    R ‚Äì Data cleaning, transformation, and analysis\n    Kaggle ‚Äì Cloud-based environment for running R scripts\n    GitHub ‚Äì Version control and project documentation\n\nüìé Dataset Source\n\nThis dataset was generated using AI (ChatGPT) to simulate real-world e-commerce transactions. It does not represent actual business data but is designed for learning and practice in data cleaning and analytics.","metadata":{}},{"cell_type":"markdown","source":"\n\nThis dataset contains **9,000+ rows** and **20+ columns** with information related to customer transactions, including order details, customer demographics, sales data, and shipping information. Below is a description of each feature:\n\n| **Column Name**       | **Description** |\n|----------------------|--------------------------------------------|\n| `Order ID`          | Unique identifier for each order. |\n| `Order Date`        | The date when the order was placed. |\n| `Ship Date`         | The date when the order was shipped. |\n| `Ship Mode`         | The shipping method used for delivery. |\n| `Customer ID`       | Unique identifier for each customer. |\n| `Customer Name`     | Full name of the customer. |\n| `Segment`          | Customer segment (e.g., Consumer, Corporate, Home Office). |\n| `Country`          | The country where the order was placed. |\n| `City`             | The city of the customer. |\n| `State`            | The state or province of the customer. |\n| `Postal Code`      | The postal code of the customer‚Äôs location. |\n| `Region`           | Geographic region (e.g., West, East, South, Central). |\n| `Product ID`       | Unique identifier for each product. |\n| `Category`         | The main product category (e.g., Furniture, Office Supplies, Technology). |\n| `Sub-Category`     | The subcategory of the product. |\n| `Product Name`     | The name of the product. |\n| `Sales`           | The total sales amount for the order. |\n| `Quantity`        | The number of items ordered. |\n| `Discount`        | The discount applied to the order. |\n| `Profit`          | The profit earned from the order. |\n\n---\n\n### **Key Characteristics of the Dataset**\n‚úî **Contains missing values, duplicates, and inconsistencies**, making it ideal for data cleaning.  \n‚úî **Includes both categorical and numerical data**, useful for exploratory data analysis.  \n‚úî **Ideal for data visualization and business insights** such as customer segmentation, sales trends, and profitability analysis.  ","metadata":{}},{"cell_type":"markdown","source":"# 3- loading the dataset","metadata":{}},{"cell_type":"code","source":"# Load necessary libraries\nlibrary(tidyverse)  # Data manipulation and visualization\nlibrary(readr)       # Reading CSV files  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:16.884573Z","iopub.execute_input":"2025-02-19T14:49:16.885908Z","iopub.status.idle":"2025-02-19T14:49:16.898334Z","shell.execute_reply":"2025-02-19T14:49:16.896918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list.files(\"/kaggle/input/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:16.900824Z","iopub.execute_input":"2025-02-19T14:49:16.901835Z","iopub.status.idle":"2025-02-19T14:49:16.916778Z","shell.execute_reply":"2025-02-19T14:49:16.915318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list.files(\"/kaggle/input/dirty-ecommerce-data-eda-r/\")  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:16.918828Z","iopub.execute_input":"2025-02-19T14:49:16.919969Z","iopub.status.idle":"2025-02-19T14:49:16.943255Z","shell.execute_reply":"2025-02-19T14:49:16.941843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Load the Dataset\ndf <- read_csv(\"/kaggle/input/dirty-ecommerce-data-eda-r/dirty_ecommerce_data.csv\")\n\n# Step 2: Preview the First Few Rows\nhead(df)\n\n# Step 3: Check the Structure of the Dataset\nstr(df)\n\n# Step 4: Summary Statistics\nsummary(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:16.945279Z","iopub.execute_input":"2025-02-19T14:49:16.946352Z","iopub.status.idle":"2025-02-19T14:49:17.113745Z","shell.execute_reply":"2025-02-19T14:49:17.111743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check parsing problems\nproblems(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.116549Z","iopub.execute_input":"2025-02-19T14:49:17.117789Z","iopub.status.idle":"2025-02-19T14:49:17.144092Z","shell.execute_reply":"2025-02-19T14:49:17.142094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the rows with invalid dates in 'OrderDate' and 'ShipDate'\ninvalid_dates <- df %>%\n  filter(is.na(OrderDate) | is.na(ShipDate))\n\n# Display the rows with invalid dates\nprint(invalid_dates)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.146802Z","iopub.execute_input":"2025-02-19T14:49:17.148281Z","iopub.status.idle":"2025-02-19T14:49:17.195904Z","shell.execute_reply":"2025-02-19T14:49:17.193963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove rows with invalid dates in 'OrderDate' or 'ShipDate'\ndf_clean <- df %>%\n  filter(!is.na(OrderDate) & !is.na(ShipDate))\n\n# Verify that the rows with invalid dates are removed\nhead(df_clean)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.198606Z","iopub.execute_input":"2025-02-19T14:49:17.199808Z","iopub.status.idle":"2025-02-19T14:49:17.243462Z","shell.execute_reply":"2025-02-19T14:49:17.241477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace invalid dates with NA\ndf$OrderDate <- as.Date(df$OrderDate, format = \"%Y-%m-%d\")\ndf$ShipDate <- as.Date(df$ShipDate, format = \"%Y-%m-%d\")\n\n# For rows where the conversion failed, replace with NA\ndf$OrderDate[is.na(df$OrderDate)] <- NA\ndf$ShipDate[is.na(df$ShipDate)] <- NA\n\n# Check again after replacement\nhead(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.246329Z","iopub.execute_input":"2025-02-19T14:49:17.247637Z","iopub.status.idle":"2025-02-19T14:49:17.293783Z","shell.execute_reply":"2025-02-19T14:49:17.291748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify if there are still any NA values in the 'OrderDate' and 'ShipDate'\nsum(is.na(df$OrderDate))  # Should return 0 if no NAs are left\nsum(is.na(df$ShipDate))   # Should return 0 if no NAs are left\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.296630Z","iopub.execute_input":"2025-02-19T14:49:17.297897Z","iopub.status.idle":"2025-02-19T14:49:17.315039Z","shell.execute_reply":"2025-02-19T14:49:17.313583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find rows with NA in OrderDate\nmissing_orderdate <- df %>%\n  filter(is.na(OrderDate))\n\n# Find rows with NA in ShipDate\nmissing_shipdate <- df %>%\n  filter(is.na(ShipDate))\n\n# Display the rows with missing dates\nprint(missing_orderdate)\nprint(missing_shipdate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.316823Z","iopub.execute_input":"2025-02-19T14:49:17.317760Z","iopub.status.idle":"2025-02-19T14:49:17.387213Z","shell.execute_reply":"2025-02-19T14:49:17.385949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace missing OrderDate and ShipDate with a placeholder date\ndf$OrderDate[is.na(df$OrderDate)] <- as.Date(\"2020-01-01\")\ndf$ShipDate[is.na(df$ShipDate)] <- as.Date(\"2020-01-01\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.388972Z","iopub.execute_input":"2025-02-19T14:49:17.389955Z","iopub.status.idle":"2025-02-19T14:49:17.400401Z","shell.execute_reply":"2025-02-19T14:49:17.399134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace missing OrderDate with the median date\nmedian_orderdate <- median(df$OrderDate, na.rm = TRUE)\ndf$OrderDate[is.na(df$OrderDate)] <- median_orderdate\n\n# Replace missing ShipDate with the median date\nmedian_shipdate <- median(df$ShipDate, na.rm = TRUE)\ndf$ShipDate[is.na(df$ShipDate)] <- median_shipdate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.402292Z","iopub.execute_input":"2025-02-19T14:49:17.403199Z","iopub.status.idle":"2025-02-19T14:49:17.416504Z","shell.execute_reply":"2025-02-19T14:49:17.415235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sum(is.na(df$OrderDate))  # Should return 0\nsum(is.na(df$ShipDate))   # Should return 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.418338Z","iopub.execute_input":"2025-02-19T14:49:17.419265Z","iopub.status.idle":"2025-02-19T14:49:17.433392Z","shell.execute_reply":"2025-02-19T14:49:17.432245Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4- exploratory data analysis-eda","metadata":{}},{"cell_type":"markdown","source":"This step involves thoroughly analyzing the dataset to understand the relationships between different features, detect patterns, and identify potential outliers. Here's a breakdown of what you can do next:","metadata":{}},{"cell_type":"markdown","source":"## 4.1- checking-missing-values","metadata":{}},{"cell_type":"code","source":"# Check for missing values in the entire dataset\nsum(is.na(df))  # This will return the total count of missing values in the dataset\n\n# Check for missing values in specific columns\nsum(is.na(df$OrderDate))  # Missing values in OrderDate column\nsum(is.na(df$ShipDate))   # Missing values in ShipDate column\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.435137Z","iopub.execute_input":"2025-02-19T14:49:17.436027Z","iopub.status.idle":"2025-02-19T14:49:17.459597Z","shell.execute_reply":"2025-02-19T14:49:17.458489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check missing values per column\ncolSums(is.na(df))  # This will give you the number of missing values for each column\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.461381Z","iopub.execute_input":"2025-02-19T14:49:17.462332Z","iopub.status.idle":"2025-02-19T14:49:17.474641Z","shell.execute_reply":"2025-02-19T14:49:17.473408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"library(naniar)\ngg_miss_upset(df)  # This creates a visualization of missing values across rows\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.476343Z","iopub.execute_input":"2025-02-19T14:49:17.477276Z","iopub.status.idle":"2025-02-19T14:49:17.991622Z","shell.execute_reply":"2025-02-19T14:49:17.990096Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This is an UpSet plot that visualizes missing values in the dataset by showing how different missing values intersect across multiple columns. Here‚Äôs an interpretation of the key aspects of the plot:\nKey Observations:\n\n    Most Frequent Missing Values:\n        The left bar chart shows the total missing values per column.\n        The columns Segment, CustomerName, ShippingCost, Region, and ProductName have missing values.\n        The highest number of missing values appears in the Segment column, followed by CustomerName and ShippingCost.\n\n    Intersection of Missing Values:\n        The vertical bars at the top represent different combinations of missing values across columns.\n        The highest intersections (tallest bars) indicate the most common missing-value patterns.\n        The first few bars (on the left) indicate that most missing values occur in a single column at a time (Segment, CustomerName, etc.).\n        Some smaller bars (on the right) show that multiple columns have missing values simultaneously for certain rows.\n\n    Set Size & Patterns:\n        The \"Set Size\" on the left shows how many missing values exist per column.\n        The dots and connecting lines below the main bar chart indicate which columns share missing values in specific rows.\n\nImplications for Data Cleaning:\n\n    Since Segment and CustomerName have significant missing values, they may require imputation or removal depending on their importance.\n    If multiple columns are missing values together (as shown in intersections), it might suggest systematic data entry issues rather than random missingness.\n    The ShippingCost column also has missing values, which could impact pricing or cost-related analysis.\n\nNext Steps:\n\n    Drop rows where too many important fields are missing.\n    Impute missing values for categorical variables (e.g., \"Unknown\" for Segment, CustomerName).\n    Use median or mean imputation for numerical values like ShippingCost.\n    Investigate why missing values occur in specific intersections.\n\nThis visualization helps in making informed decisions about handling missing data before performing further analysis. üöÄ","metadata":{}},{"cell_type":"code","source":"df <- df[!is.na(df$OrderID), ]  # Remove rows where OrderID is missing\ndf <- df[!is.na(df$PostalCode), ]  # Remove rows where PostalCode is missing\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:17.993681Z","iopub.execute_input":"2025-02-19T14:49:17.995543Z","iopub.status.idle":"2025-02-19T14:49:18.009105Z","shell.execute_reply":"2025-02-19T14:49:18.007771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df$CustomerName[is.na(df$CustomerName)] <- \"Unknown\"  # Impute with a placeholder\ndf$Segment[is.na(df$Segment)] <- \"Unknown\"  # Impute with a placeholder\ndf$Country[is.na(df$Country)] <- \"Unknown\"  # Impute with a placeholder\ndf$City[is.na(df$City)] <- \"Unknown\"  # Impute with a placeholder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.010989Z","iopub.execute_input":"2025-02-19T14:49:18.012013Z","iopub.status.idle":"2025-02-19T14:49:18.030942Z","shell.execute_reply":"2025-02-19T14:49:18.029637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df$Sales[is.na(df$Sales)] <- mean(df$Sales, na.rm = TRUE)  # Impute with mean\ndf$Quantity[is.na(df$Quantity)] <- median(df$Quantity, na.rm = TRUE)  # Impute with median\ndf$Discount[is.na(df$Discount)] <- 0  # Impute with 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.032842Z","iopub.execute_input":"2025-02-19T14:49:18.033807Z","iopub.status.idle":"2025-02-19T14:49:18.045135Z","shell.execute_reply":"2025-02-19T14:49:18.043869Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2- detecting-duplicates","metadata":{}},{"cell_type":"code","source":"# 4.2 Detecting Duplicates ------------------------------------------------------\n\n# Count duplicate rows\nduplicate_count <- sum(duplicated(df))\nprint(paste(\"Number of duplicate rows:\", duplicate_count))\n\n# Remove duplicate rows\ndf <- df[!duplicated(df), ]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.046950Z","iopub.execute_input":"2025-02-19T14:49:18.047924Z","iopub.status.idle":"2025-02-19T14:49:18.361245Z","shell.execute_reply":"2025-02-19T14:49:18.359888Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3 handling-data-types","metadata":{}},{"cell_type":"code","source":"# 4.3 Handling Data Types -------------------------------------------------------\n\n# Convert dates to proper format\ndf$OrderDate <- as.Date(df$OrderDate, format = \"%Y-%m-%d\")\ndf$ShipDate <- as.Date(df$ShipDate, format = \"%Y-%m-%d\")\n\n# Convert categorical variables to factors\ndf$Segment <- as.factor(df$Segment)\ndf$Country <- as.factor(df$Country)\ndf$Region <- as.factor(df$Region)\ndf$ProductCategory <- as.factor(df$ProductCategory)\ndf$SubCategory <- as.factor(df$SubCategory)\ndf$PaymentMethod <- as.factor(df$PaymentMethod)\n\n# Check data structure after type conversion\nstr(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.363104Z","iopub.execute_input":"2025-02-19T14:49:18.364024Z","iopub.status.idle":"2025-02-19T14:49:18.398477Z","shell.execute_reply":"2025-02-19T14:49:18.397225Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4 identifying-outliers","metadata":{}},{"cell_type":"code","source":"# 4.4 Identifying Outliers ------------------------------------------------------\n\n# Boxplots to detect outliers in numeric columns\nnumeric_cols <- c(\"Sales\", \"Quantity\", \"Discount\", \"Profit\", \"ShippingCost\")\n\npar(mfrow = c(2, 3))\nfor (col in numeric_cols) {\n  boxplot(df[[col]], main = col, col = \"lightblue\")\n}\n\n# Detect outliers using IQR method\noutlier_detection <- function(column) {\n  Q1 <- quantile(column, 0.25, na.rm = TRUE)\n  Q3 <- quantile(column, 0.75, na.rm = TRUE)\n  IQR_value <- Q3 - Q1\n  lower_bound <- Q1 - 1.5 * IQR_value\n  upper_bound <- Q3 + 1.5 * IQR_value\n  return(sum(column < lower_bound | column > upper_bound, na.rm = TRUE))\n}\n\noutliers_count <- sapply(df[, numeric_cols], outlier_detection)\nprint(outliers_count)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.400328Z","iopub.execute_input":"2025-02-19T14:49:18.401330Z","iopub.status.idle":"2025-02-19T14:49:18.544776Z","shell.execute_reply":"2025-02-19T14:49:18.543348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The boxplots represent the distribution of numerical variables in the dataset, helping to detect outliers.\n\n    Sales: The distribution appears fairly symmetric with no significant outliers.\n    Quantity: Similar to Sales, the data is well distributed without extreme values.\n    Discount: There are outliers, indicating a few transactions with unusually high discounts.\n    Profit: The data is mostly concentrated around lower values, but some high-profit transactions are visible.\n    Shipping Cost: Shows significant outliers, meaning some transactions had exceptionally high shipping costs.\n\nThe numbers on top of each category indicate the count of detected outliers, with Discount (1158) and Shipping Cost (1594) being the most affected.","metadata":{}},{"cell_type":"markdown","source":"## 4.5 feature-distribution","metadata":{}},{"cell_type":"code","source":"# 4.5 Feature Distribution ------------------------------------------------------\n\n# Histograms for numerical features\npar(mfrow = c(2, 3))\nfor (col in numeric_cols) {\n  hist(df[[col]], main = paste(\"Distribution of\", col), col = \"skyblue\", border = \"white\")\n}\n\n# Bar plots for categorical features\ncategorical_cols <- c(\"Segment\", \"Country\", \"Region\", \"ProductCategory\", \"SubCategory\", \"PaymentMethod\")\n\npar(mfrow = c(2, 3))\nfor (col in categorical_cols) {\n  barplot(table(df[[col]]), main = paste(\"Distribution of\", col), col = \"lightgreen\", las = 2)\n}\n\n# Save the cleaned dataset\nwrite.csv(df, \"cleaned_ecommerce_data.csv\", row.names = FALSE)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T14:49:18.547093Z","iopub.execute_input":"2025-02-19T14:49:18.548244Z","iopub.status.idle":"2025-02-19T14:49:18.817254Z","shell.execute_reply":"2025-02-19T14:49:18.815868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The bar plots in green display the distribution of categorical variables in the dataset:\n\n    Segment: The different customer segments are relatively evenly distributed.\n    Country: Spain has the highest number of transactions, while other countries show a more balanced distribution.\n    Region: The transaction count across regions is quite similar, indicating no strong regional imbalance.\n    Product Category: All categories have nearly equal representation.\n    SubCategory: The subcategories also appear evenly distributed.\n    Payment Method: Different payment methods are used fairly equally, with no dominant preference.\n\nOverall, the dataset appears well-distributed across categories, ensuring balanced representation for analysis.","metadata":{}},{"cell_type":"markdown","source":"# 5. Data Cleaning ","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Handling Missing Values ","metadata":{}},{"cell_type":"code","source":"# 5.1 Handling Missing Values ---------------------------------------------------\n\n# Check missing values\nmissing_values <- colSums(is.na(df))\nprint(missing_values)\n\n# Handling missing values:\n#  - Drop columns with too many missing values (threshold: 50%)\n#  - Impute missing numeric values with median\n#  - Impute missing categorical values with mode\n\nthreshold <- 0.5 * nrow(df)  # 50% threshold\ndf <- df[, colSums(is.na(df)) < threshold]  # Drop columns with too many NAs\n\nfor (col in names(df)) {\n  if (sum(is.na(df[[col]])) > 0) {\n    if (is.numeric(df[[col]])) {\n      df[[col]][is.na(df[[col]])] <- median(df[[col]], na.rm = TRUE)  # Impute numeric with median\n    } else {\n      mode_value <- names(sort(table(df[[col]]), decreasing = TRUE))[1]  # Get mode\n      df[[col]][is.na(df[[col]])] <- mode_value  # Impute categorical with mode\n    }\n  }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.819210Z","iopub.execute_input":"2025-02-19T14:49:18.820206Z","iopub.status.idle":"2025-02-19T14:49:18.853823Z","shell.execute_reply":"2025-02-19T14:49:18.852489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.2 Fixing Data Inconsistencies ","metadata":{}},{"cell_type":"code","source":"# 5.2 Fixing Data Inconsistencies ------------------------------------------------\n\n# Convert text to consistent casing\ndf$Country <- tolower(df$Country)\ndf$State <- tolower(df$State)\ndf$City <- tolower(df$City)\ndf$Region <- tolower(df$Region)\ndf$ProductCategory <- tolower(df$ProductCategory)\n\n# Trim spaces\ndf <- df %>%\n  mutate(across(where(is.character), ~trimws(.)))\n\n# Standardize categorical values\ndf$PaymentMethod <- gsub(\"Credit Card\", \"credit_card\", df$PaymentMethod, ignore.case = TRUE)\ndf$PaymentMethod <- gsub(\"PayPal\", \"paypal\", df$PaymentMethod, ignore.case = TRUE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.855739Z","iopub.execute_input":"2025-02-19T14:49:18.856771Z","iopub.status.idle":"2025-02-19T14:49:18.910558Z","shell.execute_reply":"2025-02-19T14:49:18.909086Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.3 Removing Duplicates ","metadata":{}},{"cell_type":"code","source":"# 5.3 Removing Duplicates --------------------------------------------------------\n\n# Check and remove duplicate rows\nduplicate_count <- sum(duplicated(df))\nprint(paste(\"Number of duplicate rows:\", duplicate_count))\ndf <- df[!duplicated(df), ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:18.912624Z","iopub.execute_input":"2025-02-19T14:49:18.913588Z","iopub.status.idle":"2025-02-19T14:49:19.286359Z","shell.execute_reply":"2025-02-19T14:49:19.284976Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.4 Correcting Data Types ","metadata":{}},{"cell_type":"code","source":"# 5.4 Correcting Data Types ------------------------------------------------------\n\n# Convert dates to proper format\ndf$OrderDate <- as.Date(df$OrderDate, format = \"%Y-%m-%d\")\ndf$ShipDate <- as.Date(df$ShipDate, format = \"%Y-%m-%d\")\n\n# Convert categorical variables to factors\ndf$Segment <- as.factor(df$Segment)\ndf$Country <- as.factor(df$Country)\ndf$Region <- as.factor(df$Region)\ndf$ProductCategory <- as.factor(df$ProductCategory)\ndf$SubCategory <- as.factor(df$SubCategory)\ndf$PaymentMethod <- as.factor(df$PaymentMethod)\n\n# Convert numerical columns\nnumeric_cols <- c(\"Sales\", \"Quantity\", \"Discount\", \"Profit\", \"ShippingCost\")\ndf[numeric_cols] <- lapply(df[numeric_cols], as.numeric)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:19.288333Z","iopub.execute_input":"2025-02-19T14:49:19.300593Z","iopub.status.idle":"2025-02-19T14:49:19.325307Z","shell.execute_reply":"2025-02-19T14:49:19.323983Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.5 Handling Outliers","metadata":{}},{"cell_type":"code","source":"# 5.5 Handling Outliers ----------------------------------------------------------\n\n# Detect outliers using IQR method and replace with median\nfor (col in numeric_cols) {\n  Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)\n  Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)\n  IQR_value <- Q3 - Q1\n  lower_bound <- Q1 - 1.5 * IQR_value\n  upper_bound <- Q3 + 1.5 * IQR_value\n  \n  # Replace outliers with median\n  df[[col]][df[[col]] < lower_bound | df[[col]] > upper_bound] <- median(df[[col]], na.rm = TRUE)\n}\n\n# Save the cleaned dataset\nwrite.csv(df, \"cleaned_ecommerce_data.csv\", row.names = FALSE)\n\nprint(\"Data Cleaning Complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:19.327304Z","iopub.execute_input":"2025-02-19T14:49:19.328265Z","iopub.status.idle":"2025-02-19T14:49:19.473496Z","shell.execute_reply":"2025-02-19T14:49:19.472028Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Final Cleaned Data Overview","metadata":{}},{"cell_type":"code","source":"# Final Cleaned Data Overview ---------------------------------------------\n\n# Check the structure of the cleaned dataset\nstr(df)\n\n# Check the dimensions of the dataset (rows and columns)\ncat(\"Dataset Dimensions (Rows x Columns): \", nrow(df), \"x\", ncol(df), \"\\n\")\n\n# Display summary statistics for numerical columns\nsummary(df)\n\n# Display the number of unique values for categorical columns\ncat(\"Number of unique values for categorical columns:\\n\")\ncat(\"Segment: \", length(unique(df$Segment)), \"\\n\")\ncat(\"Country: \", length(unique(df$Country)), \"\\n\")\ncat(\"Region: \", length(unique(df$Region)), \"\\n\")\ncat(\"ProductCategory: \", length(unique(df$ProductCategory)), \"\\n\")\ncat(\"SubCategory: \", length(unique(df$SubCategory)), \"\\n\")\ncat(\"PaymentMethod: \", length(unique(df$PaymentMethod)), \"\\n\")\n\n# Display a few rows of the cleaned data to verify\nhead(df)\n\n# Check for any remaining missing values (should be zero)\nmissing_values_final <- colSums(is.na(df))\ncat(\"Remaining Missing Values:\\n\")\nprint(missing_values_final)\n\n# Check for any duplicates in the cleaned dataset (should be zero)\nduplicate_count_final <- sum(duplicated(df))\ncat(\"Remaining Duplicates: \", duplicate_count_final, \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:19.475802Z","iopub.execute_input":"2025-02-19T14:49:19.476860Z","iopub.status.idle":"2025-02-19T14:49:19.743216Z","shell.execute_reply":"2025-02-19T14:49:19.742028Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Visualization &  Insights ","metadata":{}},{"cell_type":"code","source":"## 7.1 Sales Trends Over Time ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:19.744865Z","iopub.execute_input":"2025-02-19T14:49:19.745906Z","iopub.status.idle":"2025-02-19T14:49:19.753661Z","shell.execute_reply":"2025-02-19T14:49:19.752440Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load necessary libraries for plotting\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Ensure 'OrderDate' is in Date format\ndf$OrderDate <- as.Date(df$OrderDate, format=\"%Y-%m-%d\")\n\n# Create a summary of sales by Year-Month\ndf_sales_time <- df %>%\n  mutate(YearMonth = format(OrderDate, \"%Y-%m\")) %>%  # Extract Year-Month\n  group_by(YearMonth) %>%  # Group by Year-Month\n  summarise(TotalSales = sum(Sales, na.rm = TRUE))  # Summarize sales\n\n# Plot Sales Trends Over Time\nggplot(df_sales_time, aes(x = YearMonth, y = TotalSales)) +\n  geom_line(group = 1, color = \"blue\") +  # Ensure lines are drawn by connecting points\n  labs(title = \"Sales Trends Over Time\",\n       x = \"Year-Month\",\n       y = \"Total Sales\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels\n  theme_minimal()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:19.755569Z","iopub.execute_input":"2025-02-19T14:49:19.756532Z","iopub.status.idle":"2025-02-19T14:49:19.945354Z","shell.execute_reply":"2025-02-19T14:49:19.943767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ggplot(df_sales_time, aes(x = YearMonth, y = log(TotalSales + 1))) + \n  geom_line(group = 1, color = \"blue\") +\n  labs(title = \"Sales Trends Over Time (Log Scale)\",\n       x = \"Year-Month\",\n       y = \"Log of Total Sales\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  theme_minimal()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:19.947391Z","iopub.execute_input":"2025-02-19T14:49:19.948490Z","iopub.status.idle":"2025-02-19T14:49:20.125128Z","shell.execute_reply":"2025-02-19T14:49:20.123727Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.2 Customer Segmentation ","metadata":{}},{"cell_type":"code","source":"# Summarize total sales by customer\ndf_customer_sales <- df %>%\n  group_by(CustomerID) %>%\n  summarise(TotalSales = sum(Sales, na.rm = TRUE))\n\n# Plot Customer Segmentation (Top 10 customers by total sales)\ntop_customers <- df_customer_sales %>%\n  top_n(10, TotalSales) %>%\n  arrange(desc(TotalSales))\n\nggplot(top_customers, aes(x = reorder(CustomerID, -TotalSales), y = TotalSales)) +\n  geom_bar(stat = \"identity\", fill = \"orange\") +\n  labs(title = \"Top 10 Customers by Total Sales\",\n       x = \"Customer ID\",\n       y = \"Total Sales\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  theme_minimal()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:20.127268Z","iopub.execute_input":"2025-02-19T14:49:20.128337Z","iopub.status.idle":"2025-02-19T14:49:20.340270Z","shell.execute_reply":"2025-02-19T14:49:20.337749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.3 Top-Selling Products ","metadata":{}},{"cell_type":"code","source":"# Summarize total sales and quantity by product\ndf_product_sales <- df %>%\n  group_by(ProductName) %>%\n  summarise(TotalSales = sum(Sales, na.rm = TRUE), \n            TotalQuantity = sum(Quantity, na.rm = TRUE))\n\n# Plot Top 10 Selling Products by Total Sales\ntop_products_sales <- df_product_sales %>%\n  top_n(10, TotalSales) %>%\n  arrange(desc(TotalSales))\n\nggplot(top_products_sales, aes(x = reorder(ProductName, -TotalSales), y = TotalSales)) +\n  geom_bar(stat = \"identity\", fill = \"green\") +\n  labs(title = \"Top 10 Selling Products by Total Sales\",\n       x = \"Product Name\",\n       y = \"Total Sales\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  theme_minimal()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:20.343718Z","iopub.execute_input":"2025-02-19T14:49:20.345703Z","iopub.status.idle":"2025-02-19T14:49:20.516335Z","shell.execute_reply":"2025-02-19T14:49:20.514856Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.4 Regional Sales Analysis ","metadata":{}},{"cell_type":"code","source":"# Summarize total sales by region\ndf_region_sales <- df %>%\n  group_by(Region) %>%\n  summarise(TotalSales = sum(Sales, na.rm = TRUE))\n\n# Plot Regional Sales Analysis\nggplot(df_region_sales, aes(x = reorder(Region, -TotalSales), y = TotalSales)) +\n  geom_bar(stat = \"identity\", fill = \"red\") +\n  labs(title = \"Sales by Region\",\n       x = \"Region\",\n       y = \"Total Sales\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  theme_minimal()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:20.518359Z","iopub.execute_input":"2025-02-19T14:49:20.519380Z","iopub.status.idle":"2025-02-19T14:49:20.718600Z","shell.execute_reply":"2025-02-19T14:49:20.717367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.5 Discount vs Profit Relationship","metadata":{}},{"cell_type":"code","source":"# Plot Discount vs Profit Relationship\nggplot(df, aes(x = Discount, y = Profit)) +\n  geom_point(color = \"purple\", alpha = 0.5) +\n  labs(title = \"Discount vs Profit Relationship\",\n       x = \"Discount\",\n       y = \"Profit\") +\n  theme_minimal()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:20.720426Z","iopub.execute_input":"2025-02-19T14:49:20.721331Z","iopub.status.idle":"2025-02-19T14:49:21.181244Z","shell.execute_reply":"2025-02-19T14:49:21.179695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Discount vs Profit Relationship with a smoothing line\nggplot(df, aes(x = Discount, y = Profit)) +\n  geom_point(color = \"purple\", alpha = 0.5) +  # Scatter plot\n  geom_smooth(method = \"lm\", color = \"blue\", se = FALSE) +  # Linear smoothing line (no confidence interval)\n  labs(title = \"Discount vs Profit Relationship\",\n       x = \"Discount\",\n       y = \"Profit\") +\n  theme_minimal()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:21.183316Z","iopub.execute_input":"2025-02-19T14:49:21.184468Z","iopub.status.idle":"2025-02-19T14:49:21.705779Z","shell.execute_reply":"2025-02-19T14:49:21.704301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Boxplots to check for outliers\nggplot(df, aes(x = \"\", y = Discount)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Discount\")\n\nggplot(df, aes(x = \"\", y = Profit)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Profit\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:49:21.707882Z","iopub.execute_input":"2025-02-19T14:49:21.708912Z","iopub.status.idle":"2025-02-19T14:49:22.271858Z","shell.execute_reply":"2025-02-19T14:49:22.270441Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Tools & Technologies  \n\nThis project was developed and executed using the following tools:  \n\n- **Programming Language:** R  \n- **Platform:** Kaggle Notebooks  \n- **Libraries Used:**  \n  - `tidyverse` ‚Äì Data manipulation and visualization  \n  - `dplyr` ‚Äì Data wrangling  \n  - `ggplot2` ‚Äì Data visualization  \n  - `lubridate` ‚Äì Date handling  \n  - `stringr` ‚Äì String manipulation  \n  - `readr` ‚Äì Reading and writing CSV files  \n\nThe project was run entirely on Kaggle, leveraging its cloud-based environment for data analysis and visualization.  \n","metadata":{}},{"cell_type":"markdown","source":"\n## Key Takeaways from this Project:\n\nData visualizations and exploratory data analysis are essential tools for determining whether linear regression is an appropriate method for modeling the relationship between two variables.\nA linear regression model provides insights into the relationship between two variables, allowing it to be expressed quantitatively.\n\n\n# Conclusion:\n\nBased on the conducted e-commerce data analysis, several key insights have been identified:\n\n    Sales Trends: There is a clear seasonal pattern in sales over time. Identifying high-performing sales periods can help in better resource allocation and marketing strategies.\n\n    Category and Product Performance: Certain product categories consistently outperform others, contributing significantly to overall revenue. Emphasizing these categories in marketing efforts could boost sales.\n\n    Profit Margins: Analysis revealed variations in profit margins across categories and regions. Focusing on improving operational efficiency and discount strategies in low-profit areas can improve profitability.\n\n    Discount-Profit Relationship: There is an observable negative impact of high discounts on profit, suggesting the need for careful optimization of promotional offers.\n\n    Customer Segmentation Insights: Regional analysis shows differences in purchasing behavior and profitability. Targeted campaigns tailored for specific customer groups and regions may yield better results.\n\n","metadata":{"execution":{"iopub.status.busy":"2025-02-19T14:49:22.273826Z","iopub.execute_input":"2025-02-19T14:49:22.274827Z","iopub.status.idle":"2025-02-19T14:49:22.283049Z","shell.execute_reply":"2025-02-19T14:49:22.281733Z"}}}]}